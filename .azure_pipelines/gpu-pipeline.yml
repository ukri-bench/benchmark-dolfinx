# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- azure-pipelines

# trigger:
# - none

pool:
  name: ci-pool-cpu

# container:
#   # image: ghcr.io/ukri-bench/spack-buildcache-cuda:$(SHA)  # Note: SHA variable must be set in GUI
#   # image: ghcr.io/ukri-bench/spack-buildcache-cuda:cfaa8587676f548bea64d4ac6d4ce0cf8f2488c5
#   image: nvidia/cuda:12.9.1-devel-ubuntu24.04
# #   # endpoint: ghcr-io
#   options: --rm --gpus all
# #   # options: --rm --gpus all
# #   env:
# #     OMPI_ALLOW_RUN_AS_ROOT: 1
# #     OMPI_ALLOW_RUN_AS_ROOT_CONFIRM: 1
# #     PRTE_MCA_rmaps_default_mapping_policy: :oversubscribe

steps:
- task: Docker@2
  displayName: Build an image
  inputs:
    command: login
    containerRegistry: ghcr-io

- script: |
    docker pull ghcr.io/ukri-bench/spack-buildcache-cpu:e156f080fda032cb1d60ea0fdfd0aa82ac226e8c
  displayName: 'Docker pull'


# - task: CmdLine@2
#   displayName: Install toolkit
#   target: host
#   inputs:
#     script: |
#       sudo apt-get -y update
#       apt-get -y  install ca-certificates curl
#       curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
#         && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
#           sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
#           sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
#       sudo apt-get update
#       sudo apt-get install -y nvidia-container-toolkit
#       sudo nvidia-ctk runtime configure --runtime=docker
#       sudo systemctl restart docker

# Azure container jobs run as non-root user which has sudo permissions,
# but sudo is missing.  Install sudo package...
# - task: CmdLine@2
#   displayName: Install sudo package
#   target: host
#   inputs:
#     script: |
#       cid=`docker container ls -q`
#       echo "ID = $cid"
#       /usr/bin/docker exec  $cid su -c "apt-get -y update && apt-get -o DPkg::Options::="--force-confold" -y install sudo"

# - script: |
#     echo Add other tasks to build, test, and deploy your project.
#     echo See https://aka.ms/yaml
#     ls -alh /usr/local/
#     ls -alh /usr/local/bin
#   displayName: 'Run a multi-line script'

# - script: |
#     sudo apt-get -y update
#     sudo apt-get -y install wget
#     wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb
#     sudo dpkg -i cuda-keyring_1.1-1_all.deb
#     sudo apt-get -y update
#     export DEBIAN_FRONTEND=noninteractive
#     sudo apt-get install -y --no-install-recommends cuda-13.0
#   displayName: 'Install nvcc'

# - script: |
#     nvidia-smi
#     /usr/local/cuda/bin/nvcc --version
#     wget https://raw.githubusercontent.com/ukri-bench/benchmark-dolfinx/refs/heads/azure-pipelines/.azure_pipelines/test.cu
#     /usr/local/cuda/bin/nvcc test.cu
#     ./a.out
#   displayName: 'Compile and run'

# - script: |
#     bench_dolfinx --ndofs=1000 --degree=3 --qmode=0 --nreps=1 --mat_comp --float=64 --json a.json
#   displayName: Run (serial)
# - script: |
#     mpirun -n 2 bench_dolfinx --ndofs=500 --degree=3 --qmode=0 --nreps=1 --mat_comp --float=64 --json b.json
#   displayName: Run (parallel)
# - script: |
#     python src/test_output.py a.json
#     python src/test_output.py b.json
#   displayName: Post-process

# trigger:
#   branches:
#     include:
#     - '*'  # must quote since "*" is a YAML reserved character; we want a string
# pool:
#   name: ci-pool

# steps:
# - script: echo Hello, world!
#   displayName: 'Run a one-line script'

# - script: |
#     echo Add other tasks to build, test, and deploy your project.
#     echo See https://aka.ms/yaml
#     ls -alh /usr/local/
#     ls -alh /usr/local/bin
#     nvidia-smi
#   displayName: 'Run a multi-line script'

# - script: |
#     nvidia-smi
#     printf "#include <stdio.h>\n#include <cuda.h>\n__global__ void dkernel(){\nprintf(\"Hello-world\\\n\");}\n int main (){\ndkernel <<<1,1>>>();\ncudaDeviceSynchronize();\nreturn 0;}\n" > test.cu
#     /usr/local/cuda/bin/nvcc test.cu
#     echo "Run test"
#     ./a.out
#     echo "End run test"
#   displayName: 'Compile and run'
